{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPYg+LVlKN3i996C7gP5lY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambikad04/FL-ModelPoisoning/blob/main/FL_with_poisoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries Used\n",
        "The following libraries are essential for implementing and running the Federated Learning with model poisoning script:\n",
        "\n",
        "### Libraries Overview\n",
        "\n",
        "- **`torch`**: Core library for tensor computations with GPU support.\n",
        "- **`torch.nn`**: Provides tools to build and train neural networks (used to define `SimpleModel`).\n",
        "- **`torch.optim`**: Contains optimization algorithms (e.g., `SGD` for training the model).\n",
        "- **`numpy`**: Supports numerical operations (not directly used in the script but useful for data manipulation).\n",
        "\n",
        "These libraries form the backbone of the script, enabling efficient implementation of federated learning with model poisoning."
      ],
      "metadata": {
        "id": "-bGU6Yk9qj4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lgeVraFmqQos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `create_client_data`\n",
        "\n",
        "This function generates synthetic data for each client in a Federated Learning (FL) setup.\n",
        "\n",
        "\n",
        "#### **Purpose**\n",
        "To create simulated datasets for multiple clients, where each client's data includes input features (`x`) and corresponding labels (`y`).\n",
        "\n",
        "#### **Parameters**\n",
        "- **`num_clients` (int):**  \n",
        "  The number of clients for which data needs to be generated.\n",
        "  \n",
        "- **`num_samples` (int, default=100):**  \n",
        "  The number of data samples each client will have.\n",
        "\n",
        "#### **Logic**\n",
        "1. Creates random 2D feature data (`x`) for each client using `torch.randn`.\n",
        "2. Labels (`y`) are binary, based on the condition \\( x_1 + x_2 > 0 \\).\n",
        "3. Stores datasets as `(x, y)` in a dictionary with keys like `'client_0'`, `'client_1'`, etc.\n",
        "\n",
        "\n",
        "This function creates independent datasets for clients, ideal for federated training."
      ],
      "metadata": {
        "id": "V1uStmX8q-wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for client data\n",
        "def create_client_data(num_clients, num_samples=100):\n",
        "    data = {}\n",
        "    for i in range(num_clients):\n",
        "        x = torch.randn(num_samples, 2)\n",
        "        y = (x[:, 0] + x[:, 1] > 0).float().reshape(-1, 1)\n",
        "        data[f'client_{i}'] = (x, y)\n",
        "    return data"
      ],
      "metadata": {
        "id": "5Nj3hH8uqTfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class: `SimpleModel`\n",
        "\n",
        "A simple feedforward neural network designed for binary classification tasks. It processes input features through a fully connected layer followed by a sigmoid activation, outputting probabilities that represent the likelihood of belonging to one of two classes.\n",
        "\n",
        "\n",
        "#### **Structure**\n",
        "1. **Fully Connected Layer (`fc`)**: Maps 2 input features to 1 output.\n",
        "2. **Sigmoid Activation**: Converts output to probabilities (0-1).\n",
        "\n",
        "\n",
        "#### **Methods**\n",
        "- `__init__`: Initializes the model layers.\n",
        "- `forward`: Defines the forward pass:  \n",
        "  Input → Fully Connected Layer → Sigmoid Activation.\n",
        "\n",
        "This lightweight model is ideal for binary classification in Federated Learning setups."
      ],
      "metadata": {
        "id": "CuHmGqYkj_bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for neural network\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.fc(x))"
      ],
      "metadata": {
        "id": "cd5Q4_GtqZMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `train_local_model`\n",
        "\n",
        "Trains a local model on client data using a binary classification loss. This function simulates the local training process for Federated Learning, where each client trains its model independently before sharing updates with the global model.\n",
        "\n",
        "\n",
        "#### **Parameters**\n",
        "- `model`: The PyTorch model to be trained.\n",
        "- `data`: Tuple `(x, y)` with input features and true labels.\n",
        "- `epochs` (default=5): Number of training iterations.\n",
        "- `lr` (default=0.01): Learning rate for the optimizer.\n",
        "\n",
        "\n",
        "#### **Logic**\n",
        "1. Uses `nn.BCELoss` for binary classification loss.\n",
        "2. Optimizes with `SGD` over specified epochs.\n",
        "3. Updates model weights via backpropagation.\n",
        "\n",
        "\n",
        "This function handles local model training in a Federated Learning environment."
      ],
      "metadata": {
        "id": "7TrjxWEKkVff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# local training\n",
        "def train_local_model(model, data, epochs=5, lr=0.01):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data[0]) # predict the output\n",
        "        loss = criterion(output, data[1])  # loss between the predicted values with true lebel\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "WfG9sbUlqbzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `poison_model`\n",
        "\n",
        "Introduces malicious behavior by altering the global model's parameters to simulate a poisoning attack. This function demonstrates how a malicious client can disrupt the Federated Learning process by contributing poisoned updates to the global model.\n",
        "\n",
        "\n",
        "#### **Parameters**\n",
        "- `global_model`: The current global model to be poisoned.\n",
        "- `scale` (default=10.0): Intensity of the parameter alteration.\n",
        "\n",
        "\n",
        "\n",
        "#### **Logic**\n",
        "1. Clones the global model into a `malicious_model`.\n",
        "2. Alters the parameters by adding random noise scaled by `scale`.\n",
        "3. Ensures no gradients are computed during this operation using `torch.no_grad`.\n",
        "\n",
        "\n",
        "This function simulates a malicious client's attack in a Federated Learning setup."
      ],
      "metadata": {
        "id": "hHjlD2f0lMee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Poisoning function for a malicious client\n",
        "def poison_model(global_model, scale=10.0):\n",
        "    malicious_model = SimpleModel()\n",
        "    malicious_model.load_state_dict(global_model.state_dict())  # Load global model parameters\n",
        "    with torch.no_grad():  # ignore the gredient\n",
        "        for param in malicious_model.parameters():\n",
        "            param.add_(torch.randn_like(param) * scale)\n",
        "    return malicious_model.state_dict()"
      ],
      "metadata": {
        "id": "EGs2KTLrqejc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `federated_averaging`\n",
        "\n",
        "Aggregates model updates from all clients to update the global model. This function ensures that the global model reflects the combined knowledge of client models in a Federated Learning setup.\n",
        "\n",
        "#### **Logic**\n",
        "1. Retrieves the global model's parameters (`state_dict`).\n",
        "2. Computes the average of corresponding parameters from all client models.\n",
        "3. Updates the global model with the averaged parameters.\n",
        "\n",
        "#### **Output**\n",
        "- The global model is updated with the aggregated parameters.\n",
        "\n",
        "\n",
        "This function ensures that the global model reflects the collective contributions of all clients in a Federated Learning setup."
      ],
      "metadata": {
        "id": "Oyrv0SUdlxS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Federated averaging\n",
        "def federated_averaging(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()  # get the parameter of global model\n",
        "    for key in global_state_dict:\n",
        "        global_state_dict[key] = torch.stack([client_models[i][key] for i in range(len(client_models))]).mean(dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)"
      ],
      "metadata": {
        "id": "ViZubxGsqhSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `federated_learning_with_poisoning`\n",
        "\n",
        "Simulates Federated Learning with the presence of a malicious client introducing poisoned updates. This function demonstrates how malicious behavior impacts the global model's performance while coordinating updates from honest clients.\n",
        "\n",
        "#### **Logic**\n",
        "1. **Initialization:**  \n",
        "   Creates a global model (`SimpleModel`) shared across clients.\n",
        "   \n",
        "2. **Global Training Loop:**  \n",
        "   - For each epoch:\n",
        "     - Collects updates from all clients:\n",
        "       - **Malicious Client:** Adds poisoned model updates using `poison_model`.  \n",
        "       - **Honest Clients:** Locally trains models using their data (`train_local_model`).\n",
        "     - Aggregates updates using `federated_averaging`.\n",
        "\n",
        "3. **Logging:**  \n",
        "   Prints information about malicious activity and epoch completion.\n",
        "\n",
        "4. **Output:**  \n",
        "   Returns the trained global model.\n",
        "\n",
        "This function demonstrates the impact of a malicious client in Federated Learning."
      ],
      "metadata": {
        "id": "HA5FeDillyFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Federated learning with a malicious client\n",
        "def federated_learning_with_poisoning(data, num_clients, global_epochs=3, local_epochs=5, malicious_client=0):\n",
        "    global_model = SimpleModel()\n",
        "    for epoch in range(global_epochs): # outer loop\n",
        "        client_models = []\n",
        "        for client in range(num_clients):\n",
        "            if client == malicious_client:  # If the client is malicious\n",
        "                print(f\"Client {client} is malicious in epoch {epoch + 1}.\")\n",
        "                poisoned_model_state = poison_model(global_model)  # Poison the model\n",
        "                client_models.append(poisoned_model_state)\n",
        "            else:  # to check honest clients\n",
        "                local_model = SimpleModel()\n",
        "                local_model.load_state_dict(global_model.state_dict())  # to store the global model into the local model\n",
        "                client_data = data[f'client_{client}']   # retrive the client data\n",
        "                client_model_state = train_local_model(local_model, client_data, epochs=local_epochs)\n",
        "                client_models.append(client_model_state) # add the trained model’s state\n",
        "        federated_averaging(global_model, client_models)\n",
        "        print(f\"Global epoch {epoch + 1} completed.\")\n",
        "    return global_model"
      ],
      "metadata": {
        "id": "JEX0MCp7qjdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Script\n",
        "\n",
        "Runs the Federated Learning simulation with a malicious client and evaluates the global model's performance. This script demonstrates the end-to-end process of data generation, model training, and testing in a Federated Learning setup with a malicious participant.\n",
        "\n",
        "#### **Steps**\n",
        "1. **Setup:**  \n",
        "   - Defines the total number of clients (`num_clients=5`).  \n",
        "   - Assigns a malicious client (`malicious_client_id=1`).  \n",
        "\n",
        "2. **Data Generation:**  \n",
        "   Creates synthetic data for all clients using `create_client_data`.\n",
        "\n",
        "3. **Federated Learning:**  \n",
        "   Trains the global model with client updates using `federated_learning_with_poisoning`.\n",
        "\n",
        "4. **Testing:**  \n",
        "   - Generates test data and labels.  \n",
        "   - Evaluates the global model's accuracy by comparing predictions to true labels.\n",
        "\n",
        "5. **Output:**  \n",
        "   Prints the test accuracy of the global model.\n",
        "\n",
        "This script demonstrates the workflow of Federated Learning with a malicious client."
      ],
      "metadata": {
        "id": "xWA51vh2ly0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    num_clients = 5  # Total number of clients\n",
        "    malicious_client_id = 1\n",
        "\n",
        "    client_data = create_client_data(num_clients) # generates fake client data by called 'create_client_dat'\n",
        "\n",
        "    global_model = federated_learning_with_poisoning(client_data, num_clients, malicious_client=malicious_client_id)\n",
        "\n",
        "    # testing the global model\n",
        "    test_data = torch.randn(20, 2)\n",
        "    test_labels = (test_data[:, 0] + test_data[:, 1] > 0).float().reshape(-1, 1)  # labels for the test data\n",
        "    global_model.eval()\n",
        "    predictions = global_model(test_data).round()  # Make predictions\n",
        "    accuracy = (predictions == test_labels).float().mean()  # Calculate accuracy\n",
        "    print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ye6emsgq5ik",
        "outputId": "55c307af-874a-49aa-9204-6351037fb0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1 is malicious in epoch 1.\n",
            "Global epoch 1 completed.\n",
            "Client 1 is malicious in epoch 2.\n",
            "Global epoch 2 completed.\n",
            "Client 1 is malicious in epoch 3.\n",
            "Global epoch 3 completed.\n",
            "Test Accuracy: 65.00%\n"
          ]
        }
      ]
    }
  ]
}